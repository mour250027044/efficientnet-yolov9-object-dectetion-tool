# 09_full_model.yaml
# (All custom modules enabled)
# Parameters
nc: 80

# Backbone
backbone:
  - [-1, 1, EfficientNetBackbone, ["efficientnet_b3", True, [2, 3, 4]]] # 0

# Transition & lightweight feature adapters
  - [-1, 1, Adapter, [1280, 256]]           # 1
  - [-1, 1, FABlock, [256]]                 # 2
  - [-1, 1, MyHGBlock, [256, 4, 3, 1]]      # 3
  - [-1, 1, SPDADown, [384]]                # 4
  - [-1, 1, FABlock, [384]]                 # 5
  - [-1, 1, MyHGBlock, [512, 4, 3, 1]]      # 6
  - [-1, 1, Adapter, [512, 256]]            # 7
  - [-1, 1, DropBlock, [0.1]]               # 8

# ------------------------------------------------------------------
# Neck / Top-down path (feature fusion + attention)
# ------------------------------------------------------------------
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 9
  - [[-1, 5], 1, Concat, [1]]                 # 10
  - [-1, 1, Adapter, [640, 384]]            # 11
  - [-1, 1, FABlock, [384]]                 # 12
  - [-1, 1, CBAM, [384]]                    # 13

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 14
  - [[-1, 2], 1, Concat, [1]]                 # 15
  - [-1, 1, Adapter, [640, 256]]            # 16
  - [-1, 1, FABlock, [256]]                 # 17
  - [-1, 1, CBAM, [256]]                    # 18

# ------------------------------------------------------------------
# Bottom-up path (enhanced fusion)
# ------------------------------------------------------------------
  - [-1, 1, SPDADown, [256]]                # 19
  - [[-1, 11], 1, Concat, [1]]                # 20
  - [-1, 1, Adapter, [640, 384]]            # 21
  - [-1, 1, FABlock, [384]]                 # 22
  - [-1, 1, CBAM, [384]]                    # 23

  - [-1, 1, SPDADown, [384]]                # 24
  - [[-1, 7], 1, Concat, [1]]                 # 25
  - [-1, 1, Adapter, [640, 512]]            # 26
  - [-1, 1, FABlock, [512]]                 # 27
  - [-1, 1, CBAM, [512]]                    # 28

# ------------------------------------------------------------------
# BiFPN-style multi-scale fusion (fuse P3, P4, P5)
# ------------------------------------------------------------------
  - [[17, 22, 27], 1, Concat, [1]]           # 29
  - [-1, 1, Adapter, [768, 512]]            # 30
  - [-1, 1, FABlock, [512]]                 # 31
  - [-1, 1, BiFPN, [512, 2]]                # 32
  - [-1, 1, CBAM, [512]]                    # 33

# ------------------------------------------------------------------
# ASPP + SPPF context modules (capture multi-scale context)
# ------------------------------------------------------------------
  - [-1, 1, ASPP, [512, [1, 6, 12, 18]]]    # 34
  - [-1, 1, Adapter, [512, 256]]            # 35
  - [-1, 1, FABlock, [256]]                 # 36
  - [-1, 1, SPPF, [256, 5]]                 # 37

# ------------------------------------------------------------------
# Prepare detection heads (multi-scale adapters)
# ------------------------------------------------------------------
  # !! CORRECTED layer 15 to 17 !!
  - [17, 1, Adapter, [256, 96]]             # 38 # from layer 17 (P3)
  - [21, 1, Adapter, [384, 160]]            # 39 # from layer 21 (P4)
  - [27, 1, Adapter, [512, 192]]            # 40 # from layer 27 (P5)

# ------------------------------------------------------------------
# Detect head (expects 3 inputs: P3, P4, P5)
# ------------------------------------------------------------------
  - [[38, 39, 40], 1, Detect, [nc]]         # 41